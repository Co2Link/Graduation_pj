2018-03-14 15:20:28 [scrapy.utils.log] INFO: Scrapy 1.5.0 started (bot: weibo_scrapy_api)
2018-03-14 15:20:28 [scrapy.utils.log] INFO: Versions: lxml 4.1.1.0, libxml2 2.9.5, cssselect 1.0.3, parsel 1.2.0, w3lib 1.17.0, Twisted 17.5.0, Python 3.6.2 |Continuum Analytics, Inc.| (default, Jul 20 2017, 12:30:02) [MSC v.1900 64 bit (AMD64)], pyOpenSSL 17.5.0 (OpenSSL 1.0.2n  7 Dec 2017), cryptography 2.1.4, Platform Windows-10-10.0.10586-SP0
2018-03-14 15:20:28 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'weibo_scrapy_api', 'CONCURRENT_REQUESTS_PER_IP': 300, 'DOWNLOAD_DELAY': 0.2, 'LOG_FILE': 'logs\\default\\fans\\2b2d0af6275811e8876e001a7dda7113.log', 'NEWSPIDER_MODULE': 'weibo_scrapy_api.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['weibo_scrapy_api.spiders']}
2018-03-14 15:20:29 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2018-03-14 15:20:29 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2018-03-14 15:20:29 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2018-03-14 15:20:29 [scrapy.middleware] INFO: Enabled item pipelines:
['weibo_scrapy_api.pipelines.WeiboScrapyApiPipeline']
2018-03-14 15:20:29 [scrapy.core.engine] INFO: Spider opened
2018-03-14 15:20:29 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2018-03-14 15:20:29 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2018-03-14 15:20:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/robots.txt> (referer: None)
2018-03-14 15:20:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=2302833718031015_-_INFO> (referer: None)
2018-03-14 15:20:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?value=3718031015&containerid=1076033718031015&page=2> (referer: None)
2018-03-14 15:20:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/api/container/getIndex?value=3718031015&containerid=1076033718031015&page=2>

2018-03-14 15:20:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?value=3718031015&containerid=1076033718031015&page=1> (referer: None)
2018-03-14 15:20:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/api/container/getIndex?value=3718031015&containerid=1076033718031015&page=1>

2018-03-14 15:20:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?value=3718031015&containerid=1076033718031015&page=3> (referer: None)
2018-03-14 15:20:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?value=3718031015&containerid=1076033718031015&page=4> (referer: None)
2018-03-14 15:20:32 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/api/container/getIndex?value=3718031015&containerid=1076033718031015&page=3>

2018-03-14 15:20:32 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/api/container/getIndex?value=3718031015&containerid=1076033718031015&page=4>

2018-03-14 15:20:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?value=3718031015&containerid=1076033718031015&page=6> (referer: None)
2018-03-14 15:20:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?value=3718031015&containerid=1076033718031015&page=7> (referer: None)
2018-03-14 15:20:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?value=3718031015&containerid=1076033718031015&page=8> (referer: None)
2018-03-14 15:20:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?value=3718031015&containerid=1076033718031015&page=9> (referer: None)
2018-03-14 15:20:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?value=3718031015&containerid=1076033718031015&page=5> (referer: None)
2018-03-14 15:20:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/api/container/getIndex?value=3718031015&containerid=1076033718031015&page=5>

2018-03-14 15:20:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?value=3718031015&containerid=1076033718031015&page=10> (referer: None)
2018-03-14 15:20:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=1005053718031015> (referer: https://m.weibo.cn/api/container/getIndex?containerid=2302833718031015_-_INFO)
2018-03-14 15:20:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/api/container/getIndex?containerid=1005053718031015>

2018-03-14 15:20:33 [root] DEBUG: ('pages', 12)
2018-03-14 15:20:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=13> (referer: https://m.weibo.cn/api/container/getIndex?containerid=1005053718031015)
2018-03-14 15:20:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=11> (referer: https://m.weibo.cn/api/container/getIndex?containerid=1005053718031015)
2018-03-14 15:20:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=12> (referer: https://m.weibo.cn/api/container/getIndex?containerid=1005053718031015)
2018-03-14 15:20:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=10> (referer: https://m.weibo.cn/api/container/getIndex?containerid=1005053718031015)
2018-03-14 15:20:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=8> (referer: https://m.weibo.cn/api/container/getIndex?containerid=1005053718031015)
2018-03-14 15:20:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=7> (referer: https://m.weibo.cn/api/container/getIndex?containerid=1005053718031015)
2018-03-14 15:20:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=9> (referer: https://m.weibo.cn/api/container/getIndex?containerid=1005053718031015)
2018-03-14 15:20:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=6> (referer: https://m.weibo.cn/api/container/getIndex?containerid=1005053718031015)
2018-03-14 15:20:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=5> (referer: https://m.weibo.cn/api/container/getIndex?containerid=1005053718031015)
2018-03-14 15:20:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=4> (referer: https://m.weibo.cn/api/container/getIndex?containerid=1005053718031015)
2018-03-14 15:20:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=3> (referer: https://m.weibo.cn/api/container/getIndex?containerid=1005053718031015)
2018-03-14 15:20:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=2> (referer: https://m.weibo.cn/api/container/getIndex?containerid=1005053718031015)
2018-03-14 15:20:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=1> (referer: https://m.weibo.cn/api/container/getIndex?containerid=1005053718031015)
2018-03-14 15:20:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_5150766902&since_id=1> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=13)
2018-03-14 15:20:38 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_5150766902&since_id=1>

2018-03-14 15:20:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=2302835150766902_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=13)
2018-03-14 15:20:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_5071910972&since_id=1> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=13)
2018-03-14 15:20:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/api/container/getIndex?containerid=2302835150766902_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=13)
Traceback (most recent call last):
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Python\Graduation_pj\DjangoVisual\weibo_scrapy_api\weibo_scrapy_api\spiders\fans_spider.py", line 116, in parse_fans_2
    item=fans_1_Item(**response.meta)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 56, in __init__
    self[k] = v
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 66, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'fans_1_Item does not support field: depth'
2018-03-14 15:20:38 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_5071910972&since_id=1>

2018-03-14 15:20:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=2302835071910972_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=13)
2018-03-14 15:20:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/api/container/getIndex?containerid=2302835071910972_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=13)
Traceback (most recent call last):
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Python\Graduation_pj\DjangoVisual\weibo_scrapy_api\weibo_scrapy_api\spiders\fans_spider.py", line 116, in parse_fans_2
    item=fans_1_Item(**response.meta)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 56, in __init__
    self[k] = v
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 66, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'fans_1_Item does not support field: depth'
2018-03-14 15:20:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=2302835370476253_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=13)
2018-03-14 15:20:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_5370476253&since_id=1> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=13)
2018-03-14 15:20:39 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/api/container/getIndex?containerid=2302835370476253_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=13)
Traceback (most recent call last):
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Python\Graduation_pj\DjangoVisual\weibo_scrapy_api\weibo_scrapy_api\spiders\fans_spider.py", line 116, in parse_fans_2
    item=fans_1_Item(**response.meta)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 56, in __init__
    self[k] = v
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 66, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'fans_1_Item does not support field: depth'
2018-03-14 15:20:39 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_5370476253&since_id=1>

2018-03-14 15:20:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3259047691&since_id=1> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=12)
2018-03-14 15:20:40 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3259047691&since_id=1>

2018-03-14 15:20:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_5285839623&since_id=1> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=10)
2018-03-14 15:20:40 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_5285839623&since_id=1>

2018-03-14 15:20:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_5330877336&since_id=1> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=8)
2018-03-14 15:20:42 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_5330877336&since_id=1>

2018-03-14 15:20:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_5538231301&since_id=1> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=7)
2018-03-14 15:20:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_2314453571&since_id=1> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=9)
2018-03-14 15:20:43 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_5538231301&since_id=1>

2018-03-14 15:20:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=2302832384848411_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=6)
2018-03-14 15:20:44 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_2314453571&since_id=1>

2018-03-14 15:20:44 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/api/container/getIndex?containerid=2302832384848411_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=6)
Traceback (most recent call last):
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Python\Graduation_pj\DjangoVisual\weibo_scrapy_api\weibo_scrapy_api\spiders\fans_spider.py", line 116, in parse_fans_2
    item=fans_1_Item(**response.meta)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 56, in __init__
    self[k] = v
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 66, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'fans_1_Item does not support field: depth'
2018-03-14 15:20:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_5167368152&since_id=1> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=3)
2018-03-14 15:20:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_5239652046&since_id=1> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=4)
2018-03-14 15:20:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_2384848411&since_id=1> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=6)
2018-03-14 15:20:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_5167368152&since_id=1>

2018-03-14 15:20:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_6206266567&since_id=1> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=2)
2018-03-14 15:20:47 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_5239652046&since_id=1>

2018-03-14 15:20:48 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_2384848411&since_id=1>

2018-03-14 15:20:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=2302831875823145_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=1)
2018-03-14 15:20:48 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_6206266567&since_id=1>

2018-03-14 15:20:48 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/api/container/getIndex?containerid=2302831875823145_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=1)
Traceback (most recent call last):
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Python\Graduation_pj\DjangoVisual\weibo_scrapy_api\weibo_scrapy_api\spiders\fans_spider.py", line 116, in parse_fans_2
    item=fans_1_Item(**response.meta)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 56, in __init__
    self[k] = v
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 66, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'fans_1_Item does not support field: depth'
2018-03-14 15:20:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3927350856&since_id=1> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=1)
2018-03-14 15:20:49 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3927350856&since_id=1>

2018-03-14 15:20:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_1875823145&since_id=1> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=1)
2018-03-14 15:20:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=2302833927350856_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=1)
2018-03-14 15:20:50 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_1875823145&since_id=1>

2018-03-14 15:20:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_5851946592&since_id=1> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=1)
2018-03-14 15:20:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/api/container/getIndex?containerid=2302833927350856_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=1)
Traceback (most recent call last):
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Python\Graduation_pj\DjangoVisual\weibo_scrapy_api\weibo_scrapy_api\spiders\fans_spider.py", line 116, in parse_fans_2
    item=fans_1_Item(**response.meta)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 56, in __init__
    self[k] = v
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 66, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'fans_1_Item does not support field: depth'
2018-03-14 15:20:50 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_5851946592&since_id=1>

2018-03-14 15:20:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=2302835851946592_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=1)
2018-03-14 15:20:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/api/container/getIndex?containerid=2302835851946592_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=1)
Traceback (most recent call last):
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Python\Graduation_pj\DjangoVisual\weibo_scrapy_api\weibo_scrapy_api\spiders\fans_spider.py", line 116, in parse_fans_2
    item=fans_1_Item(**response.meta)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 56, in __init__
    self[k] = v
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 66, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'fans_1_Item does not support field: depth'
2018-03-14 15:20:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=2302835243264284_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=1)
2018-03-14 15:20:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/api/container/getIndex?containerid=2302835243264284_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=1)
Traceback (most recent call last):
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Python\Graduation_pj\DjangoVisual\weibo_scrapy_api\weibo_scrapy_api\spiders\fans_spider.py", line 116, in parse_fans_2
    item=fans_1_Item(**response.meta)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 56, in __init__
    self[k] = v
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 66, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'fans_1_Item does not support field: depth'
2018-03-14 15:20:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_5243264284&since_id=1> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=1)
2018-03-14 15:20:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_1821730192&since_id=1> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=1)
2018-03-14 15:20:52 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_5243264284&since_id=1>

2018-03-14 15:20:52 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_1821730192&since_id=1>

2018-03-14 15:20:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=2302831821730192_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=1)
2018-03-14 15:20:52 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_6275127965&since_id=1> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=1)
2018-03-14 15:20:52 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/api/container/getIndex?containerid=2302831821730192_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=1)
Traceback (most recent call last):
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Python\Graduation_pj\DjangoVisual\weibo_scrapy_api\weibo_scrapy_api\spiders\fans_spider.py", line 116, in parse_fans_2
    item=fans_1_Item(**response.meta)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 56, in __init__
    self[k] = v
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 66, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'fans_1_Item does not support field: depth'
2018-03-14 15:20:53 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_6275127965&since_id=1>

2018-03-14 15:20:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=2302836275127965_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=1)
2018-03-14 15:20:53 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_6411663521&since_id=1> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=1)
2018-03-14 15:20:53 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/api/container/getIndex?containerid=2302836275127965_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=1)
Traceback (most recent call last):
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Python\Graduation_pj\DjangoVisual\weibo_scrapy_api\weibo_scrapy_api\spiders\fans_spider.py", line 116, in parse_fans_2
    item=fans_1_Item(**response.meta)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 56, in __init__
    self[k] = v
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 66, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'fans_1_Item does not support field: depth'
2018-03-14 15:20:54 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_6411663521&since_id=1>

2018-03-14 15:20:54 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=2302836411663521_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=1)
2018-03-14 15:20:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/api/container/getIndex?containerid=2302836411663521_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=1)
Traceback (most recent call last):
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Python\Graduation_pj\DjangoVisual\weibo_scrapy_api\weibo_scrapy_api\spiders\fans_spider.py", line 116, in parse_fans_2
    item=fans_1_Item(**response.meta)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 56, in __init__
    self[k] = v
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 66, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'fans_1_Item does not support field: depth'
2018-03-14 15:20:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_2828656854&since_id=1> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=1)
2018-03-14 15:20:55 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_5219878167&since_id=1> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=1)
2018-03-14 15:20:56 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_2828656854&since_id=1>

2018-03-14 15:20:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=2302832828656854_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=1)
2018-03-14 15:20:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_6104470663&since_id=1> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=1)
2018-03-14 15:20:56 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=2302835219878167_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=1)
2018-03-14 15:20:57 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_5219878167&since_id=1>

2018-03-14 15:20:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=2302836104470663_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=1)
2018-03-14 15:20:57 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/api/container/getIndex?containerid=2302832828656854_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=1)
Traceback (most recent call last):
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Python\Graduation_pj\DjangoVisual\weibo_scrapy_api\weibo_scrapy_api\spiders\fans_spider.py", line 116, in parse_fans_2
    item=fans_1_Item(**response.meta)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 56, in __init__
    self[k] = v
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 66, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'fans_1_Item does not support field: depth'
2018-03-14 15:20:57 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_6104470663&since_id=1>

2018-03-14 15:20:57 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/api/container/getIndex?containerid=2302835219878167_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=1)
Traceback (most recent call last):
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Python\Graduation_pj\DjangoVisual\weibo_scrapy_api\weibo_scrapy_api\spiders\fans_spider.py", line 116, in parse_fans_2
    item=fans_1_Item(**response.meta)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 56, in __init__
    self[k] = v
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 66, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'fans_1_Item does not support field: depth'
2018-03-14 15:20:57 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/api/container/getIndex?containerid=2302836104470663_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=1)
Traceback (most recent call last):
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Python\Graduation_pj\DjangoVisual\weibo_scrapy_api\weibo_scrapy_api\spiders\fans_spider.py", line 116, in parse_fans_2
    item=fans_1_Item(**response.meta)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 56, in __init__
    self[k] = v
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 66, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'fans_1_Item does not support field: depth'
2018-03-14 15:20:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_2912165441&since_id=1> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=1)
2018-03-14 15:20:58 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_2912165441&since_id=1>

2018-03-14 15:20:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=2302832912165441_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=1)
2018-03-14 15:20:58 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_6485880700&since_id=1> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=1)
2018-03-14 15:20:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/api/container/getIndex?containerid=2302832912165441_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=1)
Traceback (most recent call last):
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Python\Graduation_pj\DjangoVisual\weibo_scrapy_api\weibo_scrapy_api\spiders\fans_spider.py", line 116, in parse_fans_2
    item=fans_1_Item(**response.meta)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 56, in __init__
    self[k] = v
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 66, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'fans_1_Item does not support field: depth'
2018-03-14 15:20:59 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_6485880700&since_id=1>

2018-03-14 15:20:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_6109906749&since_id=1> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=1)
2018-03-14 15:20:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=2302836485880700_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=1)
2018-03-14 15:21:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_6109906749&since_id=1>

2018-03-14 15:21:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_6390382956&since_id=1> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=1)
2018-03-14 15:21:00 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/api/container/getIndex?containerid=2302836485880700_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=1)
Traceback (most recent call last):
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Python\Graduation_pj\DjangoVisual\weibo_scrapy_api\weibo_scrapy_api\spiders\fans_spider.py", line 116, in parse_fans_2
    item=fans_1_Item(**response.meta)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 56, in __init__
    self[k] = v
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 66, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'fans_1_Item does not support field: depth'
2018-03-14 15:21:00 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_6390382956&since_id=1>

2018-03-14 15:21:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=2302836390382956_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=1)
2018-03-14 15:21:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=2302836109906749_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=1)
2018-03-14 15:21:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/api/container/getIndex?containerid=2302836390382956_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=1)
Traceback (most recent call last):
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Python\Graduation_pj\DjangoVisual\weibo_scrapy_api\weibo_scrapy_api\spiders\fans_spider.py", line 116, in parse_fans_2
    item=fans_1_Item(**response.meta)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 56, in __init__
    self[k] = v
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 66, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'fans_1_Item does not support field: depth'
2018-03-14 15:21:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/api/container/getIndex?containerid=2302836109906749_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=1)
Traceback (most recent call last):
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Python\Graduation_pj\DjangoVisual\weibo_scrapy_api\weibo_scrapy_api\spiders\fans_spider.py", line 116, in parse_fans_2
    item=fans_1_Item(**response.meta)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 56, in __init__
    self[k] = v
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 66, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'fans_1_Item does not support field: depth'
2018-03-14 15:21:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3824321365&since_id=1> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=1)
2018-03-14 15:21:02 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3824321365&since_id=1>

2018-03-14 15:21:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_6426945455&since_id=1> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=1)
2018-03-14 15:21:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=2302833824321365_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=1)
2018-03-14 15:21:03 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_6426945455&since_id=1>

2018-03-14 15:21:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=2302836426945455_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=1)
2018-03-14 15:21:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/api/container/getIndex?containerid=2302833824321365_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=1)
Traceback (most recent call last):
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Python\Graduation_pj\DjangoVisual\weibo_scrapy_api\weibo_scrapy_api\spiders\fans_spider.py", line 116, in parse_fans_2
    item=fans_1_Item(**response.meta)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 56, in __init__
    self[k] = v
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 66, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'fans_1_Item does not support field: depth'
2018-03-14 15:21:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/api/container/getIndex?containerid=2302836426945455_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=1)
Traceback (most recent call last):
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Python\Graduation_pj\DjangoVisual\weibo_scrapy_api\weibo_scrapy_api\spiders\fans_spider.py", line 116, in parse_fans_2
    item=fans_1_Item(**response.meta)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 56, in __init__
    self[k] = v
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 66, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'fans_1_Item does not support field: depth'
2018-03-14 15:21:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=2302836206266567_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=2)
2018-03-14 15:21:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/api/container/getIndex?containerid=2302836206266567_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=2)
Traceback (most recent call last):
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Python\Graduation_pj\DjangoVisual\weibo_scrapy_api\weibo_scrapy_api\spiders\fans_spider.py", line 116, in parse_fans_2
    item=fans_1_Item(**response.meta)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 56, in __init__
    self[k] = v
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 66, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'fans_1_Item does not support field: depth'
2018-03-14 15:21:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=2302833961048179_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=2)
2018-03-14 15:21:04 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/api/container/getIndex?containerid=2302833961048179_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=2)
Traceback (most recent call last):
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Python\Graduation_pj\DjangoVisual\weibo_scrapy_api\weibo_scrapy_api\spiders\fans_spider.py", line 116, in parse_fans_2
    item=fans_1_Item(**response.meta)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 56, in __init__
    self[k] = v
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 66, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'fans_1_Item does not support field: depth'
2018-03-14 15:21:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_6098689072&since_id=1> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=2)
2018-03-14 15:21:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=2302836098689072_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=2)
2018-03-14 15:21:05 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_6098689072&since_id=1>

2018-03-14 15:21:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_5375956120&since_id=1> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=2)
2018-03-14 15:21:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/api/container/getIndex?containerid=2302836098689072_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=2)
Traceback (most recent call last):
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Python\Graduation_pj\DjangoVisual\weibo_scrapy_api\weibo_scrapy_api\spiders\fans_spider.py", line 116, in parse_fans_2
    item=fans_1_Item(**response.meta)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 56, in __init__
    self[k] = v
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 66, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'fans_1_Item does not support field: depth'
2018-03-14 15:21:06 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_5375956120&since_id=1>

2018-03-14 15:21:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3961048179&since_id=1> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=2)
2018-03-14 15:21:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=2302835375956120_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=2)
2018-03-14 15:21:06 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3961048179&since_id=1>

2018-03-14 15:21:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_2372329722&since_id=1> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=2)
2018-03-14 15:21:06 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/api/container/getIndex?containerid=2302835375956120_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=2)
Traceback (most recent call last):
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Python\Graduation_pj\DjangoVisual\weibo_scrapy_api\weibo_scrapy_api\spiders\fans_spider.py", line 116, in parse_fans_2
    item=fans_1_Item(**response.meta)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 56, in __init__
    self[k] = v
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 66, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'fans_1_Item does not support field: depth'
2018-03-14 15:21:07 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_2372329722&since_id=1>

2018-03-14 15:21:07 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=2302832372329722_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=2)
2018-03-14 15:21:07 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/api/container/getIndex?containerid=2302832372329722_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=2)
Traceback (most recent call last):
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Python\Graduation_pj\DjangoVisual\weibo_scrapy_api\weibo_scrapy_api\spiders\fans_spider.py", line 116, in parse_fans_2
    item=fans_1_Item(**response.meta)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 56, in __init__
    self[k] = v
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 66, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'fans_1_Item does not support field: depth'
2018-03-14 15:21:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_6032103362&since_id=1> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=2)
2018-03-14 15:21:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=2302836032103362_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=2)
2018-03-14 15:21:08 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_6032103362&since_id=1>

2018-03-14 15:21:08 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/api/container/getIndex?containerid=2302836032103362_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=2)
Traceback (most recent call last):
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Python\Graduation_pj\DjangoVisual\weibo_scrapy_api\weibo_scrapy_api\spiders\fans_spider.py", line 116, in parse_fans_2
    item=fans_1_Item(**response.meta)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 56, in __init__
    self[k] = v
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 66, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'fans_1_Item does not support field: depth'
2018-03-14 15:21:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_2524416737&since_id=1> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=2)
2018-03-14 15:21:09 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_2524416737&since_id=1>

2018-03-14 15:21:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3817046602&since_id=1> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=2)
2018-03-14 15:21:09 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=2302832524416737_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=2)
2018-03-14 15:21:11 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3817046602&since_id=1>

2018-03-14 15:21:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=2302833817046602_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=2)
2018-03-14 15:21:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/api/container/getIndex?containerid=2302832524416737_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=2)
Traceback (most recent call last):
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Python\Graduation_pj\DjangoVisual\weibo_scrapy_api\weibo_scrapy_api\spiders\fans_spider.py", line 116, in parse_fans_2
    item=fans_1_Item(**response.meta)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 56, in __init__
    self[k] = v
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 66, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'fans_1_Item does not support field: depth'
2018-03-14 15:21:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/api/container/getIndex?containerid=2302833817046602_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=2)
Traceback (most recent call last):
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Python\Graduation_pj\DjangoVisual\weibo_scrapy_api\weibo_scrapy_api\spiders\fans_spider.py", line 116, in parse_fans_2
    item=fans_1_Item(**response.meta)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 56, in __init__
    self[k] = v
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 66, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'fans_1_Item does not support field: depth'
2018-03-14 15:21:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_2389406610&since_id=1> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=2)
2018-03-14 15:21:12 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_2389406610&since_id=1>

2018-03-14 15:21:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=2302832389406610_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=2)
2018-03-14 15:21:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_2418376643&since_id=1> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=2)
2018-03-14 15:21:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/api/container/getIndex?containerid=2302832389406610_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=2)
Traceback (most recent call last):
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Python\Graduation_pj\DjangoVisual\weibo_scrapy_api\weibo_scrapy_api\spiders\fans_spider.py", line 116, in parse_fans_2
    item=fans_1_Item(**response.meta)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 56, in __init__
    self[k] = v
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 66, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'fans_1_Item does not support field: depth'
2018-03-14 15:21:13 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_2418376643&since_id=1>

2018-03-14 15:21:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=2302832418376643_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=2)
2018-03-14 15:21:13 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/api/container/getIndex?containerid=2302832418376643_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=2)
Traceback (most recent call last):
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Python\Graduation_pj\DjangoVisual\weibo_scrapy_api\weibo_scrapy_api\spiders\fans_spider.py", line 116, in parse_fans_2
    item=fans_1_Item(**response.meta)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 56, in __init__
    self[k] = v
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 66, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'fans_1_Item does not support field: depth'
2018-03-14 15:21:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_2597047724&since_id=1> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=2)
2018-03-14 15:21:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=2302832597047724_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=2)
2018-03-14 15:21:14 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_2597047724&since_id=1>

2018-03-14 15:21:14 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/api/container/getIndex?containerid=2302832597047724_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=2)
Traceback (most recent call last):
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Python\Graduation_pj\DjangoVisual\weibo_scrapy_api\weibo_scrapy_api\spiders\fans_spider.py", line 116, in parse_fans_2
    item=fans_1_Item(**response.meta)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 56, in __init__
    self[k] = v
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 66, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'fans_1_Item does not support field: depth'
2018-03-14 15:21:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=2302835167368152_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=3)
2018-03-14 15:21:14 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/api/container/getIndex?containerid=2302835167368152_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=3)
Traceback (most recent call last):
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Python\Graduation_pj\DjangoVisual\weibo_scrapy_api\weibo_scrapy_api\spiders\fans_spider.py", line 116, in parse_fans_2
    item=fans_1_Item(**response.meta)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 56, in __init__
    self[k] = v
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 66, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'fans_1_Item does not support field: depth'
2018-03-14 15:21:14 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=2302832600406783_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=3)
2018-03-14 15:21:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/api/container/getIndex?containerid=2302832600406783_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=3)
Traceback (most recent call last):
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Python\Graduation_pj\DjangoVisual\weibo_scrapy_api\weibo_scrapy_api\spiders\fans_spider.py", line 116, in parse_fans_2
    item=fans_1_Item(**response.meta)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 56, in __init__
    self[k] = v
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 66, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'fans_1_Item does not support field: depth'
2018-03-14 15:21:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=2302835474972487_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=3)
2018-03-14 15:21:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_2600406783&since_id=1> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=3)
2018-03-14 15:21:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_5474972487&since_id=1> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=3)
2018-03-14 15:21:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/api/container/getIndex?containerid=2302835474972487_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=3)
Traceback (most recent call last):
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Python\Graduation_pj\DjangoVisual\weibo_scrapy_api\weibo_scrapy_api\spiders\fans_spider.py", line 116, in parse_fans_2
    item=fans_1_Item(**response.meta)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 56, in __init__
    self[k] = v
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 66, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'fans_1_Item does not support field: depth'
2018-03-14 15:21:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_2600406783&since_id=1>

2018-03-14 15:21:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_5516237035&since_id=1> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=3)
2018-03-14 15:21:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=2302835516237035_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=3)
2018-03-14 15:21:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_5474972487&since_id=1>

2018-03-14 15:21:16 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_5516237035&since_id=1>

2018-03-14 15:21:16 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/api/container/getIndex?containerid=2302835516237035_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=3)
Traceback (most recent call last):
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Python\Graduation_pj\DjangoVisual\weibo_scrapy_api\weibo_scrapy_api\spiders\fans_spider.py", line 116, in parse_fans_2
    item=fans_1_Item(**response.meta)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 56, in __init__
    self[k] = v
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 66, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'fans_1_Item does not support field: depth'
2018-03-14 15:21:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_5628464991&since_id=1> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=3)
2018-03-14 15:21:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_5876525990&since_id=1> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=3)
2018-03-14 15:21:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=2302835628464991_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=3)
2018-03-14 15:21:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_5628464991&since_id=1>

2018-03-14 15:21:17 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_5876525990&since_id=1>

2018-03-14 15:21:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=2302835876525990_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=3)
2018-03-14 15:21:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/api/container/getIndex?containerid=2302835628464991_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=3)
Traceback (most recent call last):
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Python\Graduation_pj\DjangoVisual\weibo_scrapy_api\weibo_scrapy_api\spiders\fans_spider.py", line 116, in parse_fans_2
    item=fans_1_Item(**response.meta)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 56, in __init__
    self[k] = v
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 66, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'fans_1_Item does not support field: depth'
2018-03-14 15:21:17 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/api/container/getIndex?containerid=2302835876525990_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=3)
Traceback (most recent call last):
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Python\Graduation_pj\DjangoVisual\weibo_scrapy_api\weibo_scrapy_api\spiders\fans_spider.py", line 116, in parse_fans_2
    item=fans_1_Item(**response.meta)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 56, in __init__
    self[k] = v
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 66, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'fans_1_Item does not support field: depth'
2018-03-14 15:21:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=2302833914818125_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=3)
2018-03-14 15:21:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3914818125&since_id=1> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=3)
2018-03-14 15:21:18 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/api/container/getIndex?containerid=2302833914818125_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=3)
Traceback (most recent call last):
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Python\Graduation_pj\DjangoVisual\weibo_scrapy_api\weibo_scrapy_api\spiders\fans_spider.py", line 116, in parse_fans_2
    item=fans_1_Item(**response.meta)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 56, in __init__
    self[k] = v
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 66, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'fans_1_Item does not support field: depth'
2018-03-14 15:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3914818125&since_id=1>

2018-03-14 15:21:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_5503088361&since_id=1> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=3)
2018-03-14 15:21:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_5659208806&since_id=1> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=3)
2018-03-14 15:21:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=2302835503088361_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=3)
2018-03-14 15:21:19 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_5503088361&since_id=1>

2018-03-14 15:21:20 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_5659208806&since_id=1>

2018-03-14 15:21:20 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/api/container/getIndex?containerid=2302835503088361_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=3)
Traceback (most recent call last):
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Python\Graduation_pj\DjangoVisual\weibo_scrapy_api\weibo_scrapy_api\spiders\fans_spider.py", line 116, in parse_fans_2
    item=fans_1_Item(**response.meta)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 56, in __init__
    self[k] = v
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 66, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'fans_1_Item does not support field: depth'
2018-03-14 15:21:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=2302835659208806_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=3)
2018-03-14 15:21:20 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/api/container/getIndex?containerid=2302835659208806_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=3)
Traceback (most recent call last):
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Python\Graduation_pj\DjangoVisual\weibo_scrapy_api\weibo_scrapy_api\spiders\fans_spider.py", line 116, in parse_fans_2
    item=fans_1_Item(**response.meta)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 56, in __init__
    self[k] = v
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 66, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'fans_1_Item does not support field: depth'
2018-03-14 15:21:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3068168051&since_id=1> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=3)
2018-03-14 15:21:21 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3068168051&since_id=1>

2018-03-14 15:21:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=2302833068168051_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=3)
2018-03-14 15:21:21 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/api/container/getIndex?containerid=2302833068168051_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=3)
Traceback (most recent call last):
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Python\Graduation_pj\DjangoVisual\weibo_scrapy_api\weibo_scrapy_api\spiders\fans_spider.py", line 116, in parse_fans_2
    item=fans_1_Item(**response.meta)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 56, in __init__
    self[k] = v
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 66, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'fans_1_Item does not support field: depth'
2018-03-14 15:21:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_5878474236&since_id=1> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=3)
2018-03-14 15:21:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=2302835878474236_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=3)
2018-03-14 15:21:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_5878474236&since_id=1>

2018-03-14 15:21:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3205563984&since_id=1> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=3)
2018-03-14 15:21:22 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/api/container/getIndex?containerid=2302835878474236_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=3)
Traceback (most recent call last):
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Python\Graduation_pj\DjangoVisual\weibo_scrapy_api\weibo_scrapy_api\spiders\fans_spider.py", line 116, in parse_fans_2
    item=fans_1_Item(**response.meta)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 56, in __init__
    self[k] = v
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 66, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'fans_1_Item does not support field: depth'
2018-03-14 15:21:22 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3205563984&since_id=1>

2018-03-14 15:21:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=2302833205563984_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=3)
2018-03-14 15:21:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/api/container/getIndex?containerid=2302833205563984_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=3)
Traceback (most recent call last):
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Python\Graduation_pj\DjangoVisual\weibo_scrapy_api\weibo_scrapy_api\spiders\fans_spider.py", line 116, in parse_fans_2
    item=fans_1_Item(**response.meta)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 56, in __init__
    self[k] = v
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 66, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'fans_1_Item does not support field: depth'
2018-03-14 15:21:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_5555593307&since_id=1> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=3)
2018-03-14 15:21:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=2302835555593307_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=3)
2018-03-14 15:21:23 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_5555593307&since_id=1>

2018-03-14 15:21:23 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/api/container/getIndex?containerid=2302835555593307_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=3)
Traceback (most recent call last):
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Python\Graduation_pj\DjangoVisual\weibo_scrapy_api\weibo_scrapy_api\spiders\fans_spider.py", line 116, in parse_fans_2
    item=fans_1_Item(**response.meta)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 56, in __init__
    self[k] = v
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 66, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'fans_1_Item does not support field: depth'
2018-03-14 15:21:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3860881954&since_id=1> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=3)
2018-03-14 15:21:24 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3860881954&since_id=1>

2018-03-14 15:21:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=2302833860881954_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=3)
2018-03-14 15:21:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_2885509534&since_id=1> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=3)
2018-03-14 15:21:24 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/api/container/getIndex?containerid=2302833860881954_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=3)
Traceback (most recent call last):
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Python\Graduation_pj\DjangoVisual\weibo_scrapy_api\weibo_scrapy_api\spiders\fans_spider.py", line 116, in parse_fans_2
    item=fans_1_Item(**response.meta)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 56, in __init__
    self[k] = v
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 66, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'fans_1_Item does not support field: depth'
2018-03-14 15:21:25 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_2885509534&since_id=1>

2018-03-14 15:21:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=2302832885509534_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=3)
2018-03-14 15:21:25 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/api/container/getIndex?containerid=2302832885509534_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=3)
Traceback (most recent call last):
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Python\Graduation_pj\DjangoVisual\weibo_scrapy_api\weibo_scrapy_api\spiders\fans_spider.py", line 116, in parse_fans_2
    item=fans_1_Item(**response.meta)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 56, in __init__
    self[k] = v
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 66, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'fans_1_Item does not support field: depth'
2018-03-14 15:21:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=2302835966664883_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=3)
2018-03-14 15:21:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_5921801294&since_id=1> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=3)
2018-03-14 15:21:25 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/api/container/getIndex?containerid=2302835966664883_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=3)
Traceback (most recent call last):
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Python\Graduation_pj\DjangoVisual\weibo_scrapy_api\weibo_scrapy_api\spiders\fans_spider.py", line 116, in parse_fans_2
    item=fans_1_Item(**response.meta)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 56, in __init__
    self[k] = v
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 66, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'fans_1_Item does not support field: depth'
2018-03-14 15:21:26 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_5921801294&since_id=1>

2018-03-14 15:21:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=2302835921801294_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=3)
2018-03-14 15:21:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=2302835239652046_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=4)
2018-03-14 15:21:26 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/api/container/getIndex?containerid=2302835921801294_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=3)
Traceback (most recent call last):
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Python\Graduation_pj\DjangoVisual\weibo_scrapy_api\weibo_scrapy_api\spiders\fans_spider.py", line 116, in parse_fans_2
    item=fans_1_Item(**response.meta)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 56, in __init__
    self[k] = v
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 66, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'fans_1_Item does not support field: depth'
2018-03-14 15:21:26 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/api/container/getIndex?containerid=2302835239652046_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=4)
Traceback (most recent call last):
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Python\Graduation_pj\DjangoVisual\weibo_scrapy_api\weibo_scrapy_api\spiders\fans_spider.py", line 116, in parse_fans_2
    item=fans_1_Item(**response.meta)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 56, in __init__
    self[k] = v
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 66, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'fans_1_Item does not support field: depth'
2018-03-14 15:21:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_5966664883&since_id=1> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=3)
2018-03-14 15:21:27 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_5966664883&since_id=1>

2018-03-14 15:21:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=2302835352134954_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=4)
2018-03-14 15:21:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_5352134954&since_id=1> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=4)
2018-03-14 15:21:27 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/api/container/getIndex?containerid=2302835352134954_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=4)
Traceback (most recent call last):
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Python\Graduation_pj\DjangoVisual\weibo_scrapy_api\weibo_scrapy_api\spiders\fans_spider.py", line 116, in parse_fans_2
    item=fans_1_Item(**response.meta)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 56, in __init__
    self[k] = v
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 66, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'fans_1_Item does not support field: depth'
2018-03-14 15:21:28 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_5352134954&since_id=1>

2018-03-14 15:21:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_5729194591&since_id=1> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=4)
2018-03-14 15:21:28 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_5729194591&since_id=1>

2018-03-14 15:21:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=2302835729194591_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=4)
2018-03-14 15:21:28 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/api/container/getIndex?containerid=2302835729194591_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=4)
Traceback (most recent call last):
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Python\Graduation_pj\DjangoVisual\weibo_scrapy_api\weibo_scrapy_api\spiders\fans_spider.py", line 116, in parse_fans_2
    item=fans_1_Item(**response.meta)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 56, in __init__
    self[k] = v
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 66, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'fans_1_Item does not support field: depth'
2018-03-14 15:21:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_5137991274&since_id=1> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=4)
2018-03-14 15:21:29 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_5137991274&since_id=1>

2018-03-14 15:21:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=2302835137991274_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=4)
2018-03-14 15:21:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/api/container/getIndex?containerid=2302835137991274_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=4)
Traceback (most recent call last):
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Python\Graduation_pj\DjangoVisual\weibo_scrapy_api\weibo_scrapy_api\spiders\fans_spider.py", line 116, in parse_fans_2
    item=fans_1_Item(**response.meta)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 56, in __init__
    self[k] = v
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 66, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'fans_1_Item does not support field: depth'
2018-03-14 15:21:29 [scrapy.extensions.logstats] INFO: Crawled 135 pages (at 135 pages/min), scraped 63 items (at 63 items/min)
2018-03-14 15:21:29 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=2302835178663729_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=4)
2018-03-14 15:21:29 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/api/container/getIndex?containerid=2302835178663729_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=4)
Traceback (most recent call last):
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Python\Graduation_pj\DjangoVisual\weibo_scrapy_api\weibo_scrapy_api\spiders\fans_spider.py", line 116, in parse_fans_2
    item=fans_1_Item(**response.meta)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 56, in __init__
    self[k] = v
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 66, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'fans_1_Item does not support field: depth'
2018-03-14 15:21:30 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3442391840&since_id=1> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=4)
2018-03-14 15:21:30 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3442391840&since_id=1>

2018-03-14 15:21:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=2302833442391840_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=4)
2018-03-14 15:21:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_5178663729&since_id=1> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=4)
2018-03-14 15:21:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_5254847663&since_id=1> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=4)
2018-03-14 15:21:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=2302835254847663_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=4)
2018-03-14 15:21:31 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/api/container/getIndex?containerid=2302833442391840_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=4)
Traceback (most recent call last):
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Python\Graduation_pj\DjangoVisual\weibo_scrapy_api\weibo_scrapy_api\spiders\fans_spider.py", line 116, in parse_fans_2
    item=fans_1_Item(**response.meta)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 56, in __init__
    self[k] = v
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 66, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'fans_1_Item does not support field: depth'
2018-03-14 15:21:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_5178663729&since_id=1>

2018-03-14 15:21:31 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_5254847663&since_id=1>

2018-03-14 15:21:31 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_5362560438&since_id=1> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=4)
2018-03-14 15:21:31 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/api/container/getIndex?containerid=2302835254847663_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=4)
Traceback (most recent call last):
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Python\Graduation_pj\DjangoVisual\weibo_scrapy_api\weibo_scrapy_api\spiders\fans_spider.py", line 116, in parse_fans_2
    item=fans_1_Item(**response.meta)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 56, in __init__
    self[k] = v
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 66, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'fans_1_Item does not support field: depth'
2018-03-14 15:21:32 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_5362560438&since_id=1>

2018-03-14 15:21:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=2302835362560438_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=4)
2018-03-14 15:21:32 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/api/container/getIndex?containerid=2302835362560438_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=4)
Traceback (most recent call last):
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Python\Graduation_pj\DjangoVisual\weibo_scrapy_api\weibo_scrapy_api\spiders\fans_spider.py", line 116, in parse_fans_2
    item=fans_1_Item(**response.meta)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 56, in __init__
    self[k] = v
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 66, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'fans_1_Item does not support field: depth'
2018-03-14 15:21:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=2302835210905679_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=4)
2018-03-14 15:21:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_5210905679&since_id=1> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=4)
2018-03-14 15:21:32 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_2662273537&since_id=1> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=4)
2018-03-14 15:21:33 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/api/container/getIndex?containerid=2302835210905679_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=4)
Traceback (most recent call last):
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Python\Graduation_pj\DjangoVisual\weibo_scrapy_api\weibo_scrapy_api\spiders\fans_spider.py", line 116, in parse_fans_2
    item=fans_1_Item(**response.meta)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 56, in __init__
    self[k] = v
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 66, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'fans_1_Item does not support field: depth'
2018-03-14 15:21:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_5210905679&since_id=1>

2018-03-14 15:21:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=2302832662273537_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=4)
2018-03-14 15:21:33 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_2662273537&since_id=1>

2018-03-14 15:21:33 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/api/container/getIndex?containerid=2302832662273537_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=4)
Traceback (most recent call last):
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Python\Graduation_pj\DjangoVisual\weibo_scrapy_api\weibo_scrapy_api\spiders\fans_spider.py", line 116, in parse_fans_2
    item=fans_1_Item(**response.meta)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 56, in __init__
    self[k] = v
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 66, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'fans_1_Item does not support field: depth'
2018-03-14 15:21:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_5580853589&since_id=1> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=5)
2018-03-14 15:21:34 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_5580853589&since_id=1>

2018-03-14 15:21:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=2302835580853589_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=5)
2018-03-14 15:21:34 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/api/container/getIndex?containerid=2302835580853589_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=5)
Traceback (most recent call last):
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Python\Graduation_pj\DjangoVisual\weibo_scrapy_api\weibo_scrapy_api\spiders\fans_spider.py", line 116, in parse_fans_2
    item=fans_1_Item(**response.meta)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 56, in __init__
    self[k] = v
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 66, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'fans_1_Item does not support field: depth'
2018-03-14 15:21:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3569495632&since_id=1> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=5)
2018-03-14 15:21:35 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3569495632&since_id=1>

2018-03-14 15:21:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=2302833569495632_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=5)
2018-03-14 15:21:35 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_2151036863&since_id=1> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=5)
2018-03-14 15:21:35 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/api/container/getIndex?containerid=2302833569495632_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=5)
Traceback (most recent call last):
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Python\Graduation_pj\DjangoVisual\weibo_scrapy_api\weibo_scrapy_api\spiders\fans_spider.py", line 116, in parse_fans_2
    item=fans_1_Item(**response.meta)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 56, in __init__
    self[k] = v
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 66, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'fans_1_Item does not support field: depth'
2018-03-14 15:21:36 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_2151036863&since_id=1>

2018-03-14 15:21:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=2302832151036863_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=5)
2018-03-14 15:21:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/api/container/getIndex?containerid=2302832151036863_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=5)
Traceback (most recent call last):
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Python\Graduation_pj\DjangoVisual\weibo_scrapy_api\weibo_scrapy_api\spiders\fans_spider.py", line 116, in parse_fans_2
    item=fans_1_Item(**response.meta)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 56, in __init__
    self[k] = v
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 66, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'fans_1_Item does not support field: depth'
2018-03-14 15:21:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_5578585093&since_id=1> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=6)
2018-03-14 15:21:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=2302835578585093_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=6)
2018-03-14 15:21:37 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_5578585093&since_id=1>

2018-03-14 15:21:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_5200190829&since_id=1> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=9)
2018-03-14 15:21:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=2302832314453571_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=9)
2018-03-14 15:21:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/api/container/getIndex?containerid=2302835578585093_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=6)
Traceback (most recent call last):
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Python\Graduation_pj\DjangoVisual\weibo_scrapy_api\weibo_scrapy_api\spiders\fans_spider.py", line 116, in parse_fans_2
    item=fans_1_Item(**response.meta)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 56, in __init__
    self[k] = v
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 66, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'fans_1_Item does not support field: depth'
2018-03-14 15:21:38 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_5200190829&since_id=1>

2018-03-14 15:21:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/api/container/getIndex?containerid=2302832314453571_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=9)
Traceback (most recent call last):
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Python\Graduation_pj\DjangoVisual\weibo_scrapy_api\weibo_scrapy_api\spiders\fans_spider.py", line 116, in parse_fans_2
    item=fans_1_Item(**response.meta)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 56, in __init__
    self[k] = v
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 66, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'fans_1_Item does not support field: depth'
2018-03-14 15:21:38 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=2302835200190829_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=9)
2018-03-14 15:21:38 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/api/container/getIndex?containerid=2302835200190829_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=9)
Traceback (most recent call last):
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Python\Graduation_pj\DjangoVisual\weibo_scrapy_api\weibo_scrapy_api\spiders\fans_spider.py", line 116, in parse_fans_2
    item=fans_1_Item(**response.meta)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 56, in __init__
    self[k] = v
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 66, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'fans_1_Item does not support field: depth'
2018-03-14 15:21:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_5507610998&since_id=1> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=9)
2018-03-14 15:21:39 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_5507610998&since_id=1>

2018-03-14 15:21:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_2143131621&since_id=1> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=9)
2018-03-14 15:21:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=2302832143131621_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=9)
2018-03-14 15:21:39 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=2302835507610998_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=9)
2018-03-14 15:21:40 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_2143131621&since_id=1>

2018-03-14 15:21:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3978644011&since_id=1> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=9)
2018-03-14 15:21:40 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/api/container/getIndex?containerid=2302832143131621_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=9)
Traceback (most recent call last):
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Python\Graduation_pj\DjangoVisual\weibo_scrapy_api\weibo_scrapy_api\spiders\fans_spider.py", line 116, in parse_fans_2
    item=fans_1_Item(**response.meta)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 56, in __init__
    self[k] = v
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 66, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'fans_1_Item does not support field: depth'
2018-03-14 15:21:40 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/api/container/getIndex?containerid=2302835507610998_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=9)
Traceback (most recent call last):
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Python\Graduation_pj\DjangoVisual\weibo_scrapy_api\weibo_scrapy_api\spiders\fans_spider.py", line 116, in parse_fans_2
    item=fans_1_Item(**response.meta)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 56, in __init__
    self[k] = v
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 66, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'fans_1_Item does not support field: depth'
2018-03-14 15:21:40 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3978644011&since_id=1>

2018-03-14 15:21:40 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=2302833978644011_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=9)
2018-03-14 15:21:40 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/api/container/getIndex?containerid=2302833978644011_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=9)
Traceback (most recent call last):
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Python\Graduation_pj\DjangoVisual\weibo_scrapy_api\weibo_scrapy_api\spiders\fans_spider.py", line 116, in parse_fans_2
    item=fans_1_Item(**response.meta)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 56, in __init__
    self[k] = v
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 66, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'fans_1_Item does not support field: depth'
2018-03-14 15:21:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_5330876828&since_id=1> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=7)
2018-03-14 15:21:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=2302835330876828_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=7)
2018-03-14 15:21:41 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_5330876828&since_id=1>

2018-03-14 15:21:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=2302835538231301_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=7)
2018-03-14 15:21:41 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/api/container/getIndex?containerid=2302835330876828_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=7)
Traceback (most recent call last):
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Python\Graduation_pj\DjangoVisual\weibo_scrapy_api\weibo_scrapy_api\spiders\fans_spider.py", line 116, in parse_fans_2
    item=fans_1_Item(**response.meta)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 56, in __init__
    self[k] = v
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 66, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'fans_1_Item does not support field: depth'
2018-03-14 15:21:41 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/api/container/getIndex?containerid=2302835538231301_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=7)
Traceback (most recent call last):
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Python\Graduation_pj\DjangoVisual\weibo_scrapy_api\weibo_scrapy_api\spiders\fans_spider.py", line 116, in parse_fans_2
    item=fans_1_Item(**response.meta)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 56, in __init__
    self[k] = v
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 66, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'fans_1_Item does not support field: depth'
2018-03-14 15:21:41 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3759974863&since_id=1> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=7)
2018-03-14 15:21:42 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3759974863&since_id=1>

2018-03-14 15:21:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=2302833759974863_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=7)
2018-03-14 15:21:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3044912854&since_id=1> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=7)
2018-03-14 15:21:42 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/api/container/getIndex?containerid=2302833759974863_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=7)
Traceback (most recent call last):
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Python\Graduation_pj\DjangoVisual\weibo_scrapy_api\weibo_scrapy_api\spiders\fans_spider.py", line 116, in parse_fans_2
    item=fans_1_Item(**response.meta)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 56, in __init__
    self[k] = v
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 66, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'fans_1_Item does not support field: depth'
2018-03-14 15:21:42 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3044912854&since_id=1>

2018-03-14 15:21:42 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=2302833044912854_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=7)
2018-03-14 15:21:43 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/api/container/getIndex?containerid=2302833044912854_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=7)
Traceback (most recent call last):
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Python\Graduation_pj\DjangoVisual\weibo_scrapy_api\weibo_scrapy_api\spiders\fans_spider.py", line 116, in parse_fans_2
    item=fans_1_Item(**response.meta)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 56, in __init__
    self[k] = v
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 66, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'fans_1_Item does not support field: depth'
2018-03-14 15:21:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=2302835330877336_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=8)
2018-03-14 15:21:43 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/api/container/getIndex?containerid=2302835330877336_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=8)
Traceback (most recent call last):
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Python\Graduation_pj\DjangoVisual\weibo_scrapy_api\weibo_scrapy_api\spiders\fans_spider.py", line 116, in parse_fans_2
    item=fans_1_Item(**response.meta)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 56, in __init__
    self[k] = v
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 66, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'fans_1_Item does not support field: depth'
2018-03-14 15:21:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=2302835285839623_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=10)
2018-03-14 15:21:43 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/api/container/getIndex?containerid=2302835285839623_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=10)
Traceback (most recent call last):
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Python\Graduation_pj\DjangoVisual\weibo_scrapy_api\weibo_scrapy_api\spiders\fans_spider.py", line 116, in parse_fans_2
    item=fans_1_Item(**response.meta)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 56, in __init__
    self[k] = v
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 66, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'fans_1_Item does not support field: depth'
2018-03-14 15:21:43 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3179126874&since_id=1> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=10)
2018-03-14 15:21:44 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3179126874&since_id=1>

2018-03-14 15:21:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=2302833259047691_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=12)
2018-03-14 15:21:44 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/api/container/getIndex?containerid=2302833259047691_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=12)
Traceback (most recent call last):
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Python\Graduation_pj\DjangoVisual\weibo_scrapy_api\weibo_scrapy_api\spiders\fans_spider.py", line 116, in parse_fans_2
    item=fans_1_Item(**response.meta)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 56, in __init__
    self[k] = v
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 66, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'fans_1_Item does not support field: depth'
2018-03-14 15:21:44 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=2302833179126874_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=10)
2018-03-14 15:21:44 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/api/container/getIndex?containerid=2302833179126874_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=10)
Traceback (most recent call last):
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Python\Graduation_pj\DjangoVisual\weibo_scrapy_api\weibo_scrapy_api\spiders\fans_spider.py", line 116, in parse_fans_2
    item=fans_1_Item(**response.meta)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 56, in __init__
    self[k] = v
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 66, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'fans_1_Item does not support field: depth'
2018-03-14 15:21:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_5376403567&since_id=1> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=12)
2018-03-14 15:21:45 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_5376403567&since_id=1>

2018-03-14 15:21:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_5384964321&since_id=1> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=12)
2018-03-14 15:21:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=2302835384964321_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=12)
2018-03-14 15:21:45 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_5395518875&since_id=1> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=11)
2018-03-14 15:21:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_5384964321&since_id=1>

2018-03-14 15:21:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=2302835395518875_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=11)
2018-03-14 15:21:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=2302835376403567_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=12)
2018-03-14 15:21:46 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/api/container/getIndex?containerid=2302835384964321_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=12)
Traceback (most recent call last):
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Python\Graduation_pj\DjangoVisual\weibo_scrapy_api\weibo_scrapy_api\spiders\fans_spider.py", line 116, in parse_fans_2
    item=fans_1_Item(**response.meta)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 56, in __init__
    self[k] = v
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 66, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'fans_1_Item does not support field: depth'
2018-03-14 15:21:46 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_5395518875&since_id=1>

2018-03-14 15:21:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3289182405&since_id=1> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=11)
2018-03-14 15:21:46 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/api/container/getIndex?containerid=2302835395518875_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=11)
Traceback (most recent call last):
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Python\Graduation_pj\DjangoVisual\weibo_scrapy_api\weibo_scrapy_api\spiders\fans_spider.py", line 116, in parse_fans_2
    item=fans_1_Item(**response.meta)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 56, in __init__
    self[k] = v
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 66, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'fans_1_Item does not support field: depth'
2018-03-14 15:21:46 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/api/container/getIndex?containerid=2302835376403567_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=12)
Traceback (most recent call last):
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Python\Graduation_pj\DjangoVisual\weibo_scrapy_api\weibo_scrapy_api\spiders\fans_spider.py", line 116, in parse_fans_2
    item=fans_1_Item(**response.meta)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 56, in __init__
    self[k] = v
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 66, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'fans_1_Item does not support field: depth'
2018-03-14 15:21:47 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3289182405&since_id=1>

2018-03-14 15:21:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=2302833289182405_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=11)
2018-03-14 15:21:47 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/api/container/getIndex?containerid=2302833289182405_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=11)
Traceback (most recent call last):
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Python\Graduation_pj\DjangoVisual\weibo_scrapy_api\weibo_scrapy_api\spiders\fans_spider.py", line 116, in parse_fans_2
    item=fans_1_Item(**response.meta)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 56, in __init__
    self[k] = v
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 66, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'fans_1_Item does not support field: depth'
2018-03-14 15:21:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=2302835376405552_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=11)
2018-03-14 15:21:48 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/api/container/getIndex?containerid=2302835376405552_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=11)
Traceback (most recent call last):
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Python\Graduation_pj\DjangoVisual\weibo_scrapy_api\weibo_scrapy_api\spiders\fans_spider.py", line 116, in parse_fans_2
    item=fans_1_Item(**response.meta)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 56, in __init__
    self[k] = v
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 66, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'fans_1_Item does not support field: depth'
2018-03-14 15:21:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_5376405552&since_id=1> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=11)
2018-03-14 15:21:48 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_5376405552&since_id=1>

2018-03-14 15:21:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_5330660500&since_id=1> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=11)
2018-03-14 15:21:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=2302835330660500_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=11)
2018-03-14 15:21:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_5376406553&since_id=1> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=11)
2018-03-14 15:21:49 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_5330660500&since_id=1>

2018-03-14 15:21:49 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/api/container/getIndex?containerid=2302835330660500_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=11)
Traceback (most recent call last):
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Python\Graduation_pj\DjangoVisual\weibo_scrapy_api\weibo_scrapy_api\spiders\fans_spider.py", line 116, in parse_fans_2
    item=fans_1_Item(**response.meta)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 56, in __init__
    self[k] = v
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 66, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'fans_1_Item does not support field: depth'
2018-03-14 15:21:49 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_5376406553&since_id=1>

2018-03-14 15:21:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=2302835376406553_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=11)
2018-03-14 15:21:49 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/api/container/getIndex?containerid=2302835376406553_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=11)
Traceback (most recent call last):
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Python\Graduation_pj\DjangoVisual\weibo_scrapy_api\weibo_scrapy_api\spiders\fans_spider.py", line 116, in parse_fans_2
    item=fans_1_Item(**response.meta)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 56, in __init__
    self[k] = v
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 66, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'fans_1_Item does not support field: depth'
2018-03-14 15:21:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_5392277341&since_id=1> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=11)
2018-03-14 15:21:49 [scrapy.core.scraper] DEBUG: Scraped from <200 https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_5392277341&since_id=1>

2018-03-14 15:21:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://m.weibo.cn/api/container/getIndex?containerid=2302835392277341_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=11)
2018-03-14 15:21:50 [scrapy.core.scraper] ERROR: Spider error processing <GET https://m.weibo.cn/api/container/getIndex?containerid=2302835392277341_-_INFO> (referer: https://m.weibo.cn/api/container/getIndex?containerid=231051_-_fans_-_3718031015&since_id=11)
Traceback (most recent call last):
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Python\Graduation_pj\DjangoVisual\weibo_scrapy_api\weibo_scrapy_api\spiders\fans_spider.py", line 116, in parse_fans_2
    item=fans_1_Item(**response.meta)
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 56, in __init__
    self[k] = v
  File "d:\anaconda2\envs\py3\envs\graduation_pj\lib\site-packages\scrapy\item.py", line 66, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'fans_1_Item does not support field: depth'
2018-03-14 15:21:50 [scrapy.core.engine] INFO: Closing spider (finished)
2018-03-14 15:21:50 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 106203,
 'downloader/request_count': 192,
 'downloader/request_method_count/GET': 192,
 'downloader/response_bytes': 567247,
 'downloader/response_count': 192,
 'downloader/response_status_count/200': 192,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2018, 3, 14, 7, 21, 50, 213019),
 'item_scraped_count': 89,
 'log_count/DEBUG': 283,
 'log_count/ERROR': 83,
 'log_count/INFO': 8,
 'request_depth_max': 3,
 'response_received_count': 192,
 'scheduler/dequeued': 191,
 'scheduler/dequeued/memory': 191,
 'scheduler/enqueued': 191,
 'scheduler/enqueued/memory': 191,
 'spider_exceptions/KeyError': 83,
 'start_time': datetime.datetime(2018, 3, 14, 7, 20, 29, 845752)}
2018-03-14 15:21:50 [scrapy.core.engine] INFO: Spider closed (finished)
